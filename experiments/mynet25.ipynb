{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6067e586-0d81-49d1-8a5a-55f98af3ee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./attention-module/MODELS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65692b77-0503-493c-8b53-aba7405cdb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from cbam import CBAM\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torchvision.models.resnet import BasicBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebfda728-d810-428a-8ff4-e172587f9471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BasicBlock taken from Resnet Paper https://arxiv.org/pdf/1512.03385\n",
    "\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, 3)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.cbam1 = CBAM(64)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 3)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.cbam2 = CBAM(128)\n",
    "\n",
    "        self.resblock1 = BasicBlock(128, 128)\n",
    "        self.cbamres1 = CBAM(128)\n",
    "        self.resblock1a = BasicBlock(128,128)\n",
    "        self.resblock1b = BasicBlock(128,128)\n",
    "        self.resblock1c = BasicBlock(128,128)\n",
    "        downsample = nn.Sequential(\n",
    "            nn.Conv2d(128, 256, kernel_size=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "        )\n",
    "\n",
    "        self.resblock2 = BasicBlock(128, 256, stride=2, downsample=downsample)\n",
    "        self.cbamres2 = CBAM(256)\n",
    "\n",
    "      \n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc1 = nn.Linear(256, 200)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        #x = self.cbam1(x)\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        #x = self.cbam2(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.resblock1(x)\n",
    "        x = self.resblock1a(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.resblock1b(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.resblock1c(x)\n",
    "        x = self.cbamres1(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.resblock2(x)\n",
    "        x = self.cbamres2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.adaptive_pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d21f932-f779-44f5-8cd5-8b4962baa63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of validation dataset 300\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55bee269c45b4c15b1ffe17d657d33e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Training Loss 5.186112305051953. Validation Loss 5.051032962799073 Accuracy 1.6666666666666667\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "812812a13041420f837e623d29bc7c58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Training Loss 4.807513575491924. Validation Loss 4.492236652374268 Accuracy 3.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e2da55d1894fc899cb202b017852ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Training Loss 4.448487560163684. Validation Loss 4.363850905100505 Accuracy 3.6666666666666665\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86b96c2c6a714e839a2d7f077b83adce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Training Loss 4.180001729992678. Validation Loss 4.067730433146159 Accuracy 8.333333333333334\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11ef92f1fe0149d4ae5187f18b8ecd5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Training Loss 3.915256171633496. Validation Loss 3.737173341115316 Accuracy 12.333333333333334\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d2d771ba4f3427fa55bf2a72df13df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Training Loss 3.6691769616495824. Validation Loss 3.580542573928833 Accuracy 13.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "048fb2ed2fe047ebb920cc12dc619bab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Training Loss 3.4050442548563575. Validation Loss 3.6652168305714925 Accuracy 15.333333333333334\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e41f5aa94f24db5b7a187ef771a6ee8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Training Loss 3.1762597550833314. Validation Loss 3.325432119369507 Accuracy 19.333333333333332\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9251ed9e6c1b4f6f87fd99290c904a12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Training Loss 2.9646182162409125. Validation Loss 3.107712694803874 Accuracy 22.333333333333332\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "068b92d0cd9a424fb99093f6b5a01079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Training Loss 2.769148322963949. Validation Loss 3.239995126724243 Accuracy 22.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2598eaf1bb944e26824e7dae6486f2f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Training Loss 2.536209732262679. Validation Loss 3.138105853398641 Accuracy 25.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b053c5777ebe4d2b8b2bb2484dea8035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Training Loss 2.3203180322824632. Validation Loss 3.1017212931315106 Accuracy 26.666666666666668\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19662a913a304d1eb52ff1581f68e881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 Training Loss 2.096459613836226. Validation Loss 3.118009703954061 Accuracy 28.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f574cf2800c94fa083db1a7290c816fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 Training Loss 1.9186658805656902. Validation Loss 2.95381454149882 Accuracy 26.333333333333332\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "952cc9ab34a144f18196d2052c92474a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Training Loss 1.7164296691862373. Validation Loss 3.5202336343129477 Accuracy 23.333333333333332\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c447ce368a463cab4c45bccfe0849b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 Training Loss 1.495942937017199. Validation Loss 3.083222942352295 Accuracy 28.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d62555387ba463c9bedf25deb4fd42f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 Training Loss 1.3324064606317185. Validation Loss 3.1985652923583983 Accuracy 29.666666666666668\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62f8a87176cb4b6b9a4b7002d6996006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 Training Loss 1.1647544509074041. Validation Loss 3.4826162560780842 Accuracy 26.666666666666668\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0421ce876151439a829246f47bf244c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 Training Loss 0.9832948446483163. Validation Loss 3.3762538274129232 Accuracy 26.333333333333332\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bb280d3db2340079b52c2398fbeec1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 Training Loss 0.8310496207074111. Validation Loss 3.4600459639231365 Accuracy 26.666666666666668\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "039455077cfb4832804da8caf321ab06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 Training Loss 0.7280132149578104. Validation Loss 3.7588232549031577 Accuracy 25.333333333333332\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e01bdd61f57d4ca390ccad44dbebd2f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 63\u001b[0m\n\u001b[1;32m     61\u001b[0m prediction \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[1;32m     62\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function(prediction, labels)\n\u001b[0;32m---> 63\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     65\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m images\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# I looked up how to bold words so I could make test accuracy more visible in output\n",
    "bold_start = \"\\033[1m\"\n",
    "bold_end = \"\\033[0m\"\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.Resize((224, 224)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "num_classes = 200\n",
    "\n",
    "def create_list_of_epochs(epochs):\n",
    "    list_of_epochs = []\n",
    "    for epoch in range(epochs):\n",
    "        list_of_epochs.append(epoch)\n",
    "    return list_of_epochs\n",
    "\n",
    "\n",
    "train_dataset = datasets.ImageFolder(\"CUB_200_2011_reorganized/train\",\n",
    "                                     transform=transform)\n",
    "length_of_inital_train_dataset = int(0.95 * len(train_dataset))\n",
    "length_of_validation_dataset = len(train_dataset) - length_of_inital_train_dataset\n",
    "train_dataset, validation_dataset = random_split(\n",
    "    train_dataset, [length_of_inital_train_dataset, length_of_validation_dataset])\n",
    "test_dataset = datasets.ImageFolder(\"CUB_200_2011_reorganized/test\",\n",
    "                                    transform=transform)\n",
    "\n",
    "print(f\"size of validation dataset {len(validation_dataset)}\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
    "validation_loader = DataLoader(validation_dataset, shuffle=False, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "model = MyNet()\n",
    "model = nn.DataParallel(model)\n",
    "model = model.to(device)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "#scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=2, eta_min=1e-6)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "validation_loss_tracker = []\n",
    "\n",
    "list_of_training_loss = []\n",
    "\n",
    "#model.summary()\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        prediction = model(images)\n",
    "        loss = loss_function(prediction, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "    training_loss_for_epoch = running_loss/len(train_dataset)\n",
    "    list_of_training_loss.append(training_loss_for_epoch)\n",
    "\n",
    "    model.eval()\n",
    "    validation_loss = 0\n",
    "    correct_for_validation = 0\n",
    "    total_for_validation = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in validation_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            validation_loss += loss.item() * images.size(0)\n",
    "            nothing, predicted = torch.max(outputs.data, 1)\n",
    "            total_for_validation += labels.size(0)\n",
    "            correct_for_validation += (predicted == labels).sum().item()\n",
    "    avg_val_loss = validation_loss / len(validation_dataset)\n",
    "    validation_loss_tracker.append(avg_val_loss)\n",
    "    accuracy = 100 * correct_for_validation / total_for_validation\n",
    "    print(f\"Epoch {epoch} Training Loss {training_loss_for_epoch}. Validation Loss {avg_val_loss} Accuracy {accuracy}\")\n",
    "    #scheduler.step()\n",
    "\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        model.eval()\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        nothing, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'{bold_start}Test Accuracy: {100 * correct // total} % {bold_end}')\n",
    "\n",
    "\n",
    "list_of_epochs = create_list_of_epochs(epochs)\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Training loss\")\n",
    "plt.title(\"Training loss epochs\")\n",
    "plt.plot(list_of_epochs, list_of_training_loss, label=\"Training Loss\")\n",
    "plt.plot(list_of_epochs, validation_loss_tracker, label=\"Validation loss\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd095fab-b591-40bc-85c7-7c12b877caec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
